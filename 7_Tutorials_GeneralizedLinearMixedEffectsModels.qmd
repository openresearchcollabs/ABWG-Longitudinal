---
title: "Generalized Linear Mixed Effects Models"
author: "Biostatistics Working Group"
---

## Overview
Generalized linear mixed-effects models (GLMMs) are a statistical methodology used to model both fixed effects and random variability. These models accommodate non-normal data and hierarchical or nested data structures. They extend the general linear model (GLM) to a mixed-effects framework which includes both fixed effects, which capture population-level trends, and random effects, which account for individual or group-specific variability. This particularly valuable for longitudinal studies where there is a need to capture both overarching trends and individual-specific trajectories. The mixed model approach allows for accomodating diverse data distributions while simultaneously capturing both the grand mean trend (fixed effect) and deviations specific to individual or groups (random effects). 

[+add diagrams/figures]

### When to use Longitudinal Generalized Linear Mixed Effects Models?
You should employ longitudinal generalized linear mixed effects models in the following scenarios:

1. You want to know: How individual trajectories change over time while accounting for within-subject correlations.
2. Your variable: Is recorded over multiple time points and may not necessarily follow a normal distribution.
3. You have: Longitudinal data where measurements within subjects are correlated and you want to capture both fixed (population-level) and random (subject-specific) effects in your analysis.

### Getting Started with Longitudinal Generalized Linear Mixed Effects Models
In this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:

1. Understand the basic principles of GLMMs in longitudinal settings.
2. Fit GLMMs to longitudinal data in R.
3. Analyze and interpret results derived from GLMM analysis.

## Basic Example
In this tutorial, we will begin by generating a sample dataset directly within R to ensure everyone has the same starting point and can follow along without needing to download or access external files. This generated dataset will serve as our example throughout this tutorial. In your own analyses, you'll likely start by importing your own data.

The simulated dataset created for this example consists of scores on a single outcome variable ("Job_Satisfaction") for 500 individuals each measured at four time points: T1-T4. 

#### Create Example Dataset
```{r}

# This will create a dataset with 2000 rows (4 rows for each of the 500 individuals).

# Setting the number of individuals for our sample data
n <- 500

# Specifying the desired correlation matrix for our data
cor_matrix <- matrix(c(1, 0.30, 0.30, 0.30, 
                      0.30, 1, 0.30, 0.30, 
                      0.30, 0.30, 1, 0.30,
                      0.30, 0.30, 0.30, 1),
                      nrow=4)

# Using Cholesky decomposition to generate correlated data
cholesky <- chol(cor_matrix)

# Generating correlated random data for 4 timepoints
random_data <- matrix(rnorm(n * 4), ncol=4)
correlated_data <- random_data %*% cholesky

# Convert the correlated data to probabilities using the plogis function
correlated_probs <- plogis(correlated_data)

# Convert the probabilities to binary outcomes (using 0.5 as the threshold)
binary_outcomes <- ifelse(correlated_probs > 0.5, 1, 0)

# Converting the generated data into a structured data frame
data <- data.frame(
  Individual = rep(1:n, each=4),
  TimePoint = rep(c("T1", "T2", "T3", "T4"), times=n),
  Job_Satisfaction = as.vector(t(binary_outcomes))
)

```

### View Dataset
```{r}
head(data)
```

### Model Specification and Estimation
To specify a Generalized Linear Mixed Effects Model (GLMM), we will use the `lme4` package in R to establish both the fixed and random effects in our model, accounting for the nested or hierarchical structure of the data by introducing random effects. This approach allows us to model non-normally distributed outcome variables, while capturing both fixed and random effects.

#### Install and Load Necessary Libraries
```{r}
if (!("lme4" %in% installed.packages())) install.packages("lme4")
library(lme4)

```

#### Model
```{r}
model <- glmer(Job_Satisfaction ~ TimePoint + (1 | Individual), data = data, family = binomial(link = "logit"))
```

#### Model Summary
```{r}
print(model)
```

```{r}
## Creating variable (names) from output to be used for inline text

p_value_T2 <- summary(model)$coefficients["TimePointT2", "Pr(>|z|)"]
p_value_T3 <- summary(model)$coefficients["TimePointT3", "Pr(>|z|)"]
coeff_T3 <- summary(model)$coefficients["TimePointT3", 3]

```

### Interpreting the Results
A Generalized linear mixed-effects model (GLMM) was employed to understand the relationship between Job Satisfaction and TimePoint while accounting for the random effects associated with individuals. The model assumes a binomial distribution for Job Satisfaction with a logit link function.

From the `glmer` output, we can gather key information:
- Fixed effects coefficients, which give us information about the change in the log odds of Job Satisfaction for a unit change in TimePoint.
- Random effects variance components, which quantify the variability in intercepts across individuals.

For a comprehensive interpretation, we would look at:
- Coefficient (Estimate) for `TimePoint`: `r coeff_T3`
- Associated p-value: `r p_value_T2`)

## Conclusion
If the p-value for the `TimePoint` coefficient is less than 0.05, we can conclude that there's a statistically significant change in Job Satisfaction across the TimePoints according to the GLMM. Otherwise, there isn't sufficient evidence to support such a change. The direction (increase or decrease) of this change is indicated by the sign of the coefficient for `TimePoint`.

