correlated_data <- random_data %*% cholesky
# Converting the generated data into a structured data frame in wide format
data_wide <- data.frame(
Individual = 1:n,
Job_Satisfaction_T1 = round(runif(n, 5, 10)),
Job_Satisfaction_T2 = round(runif(n, 5, 10)),
Job_Satisfaction_T3 = round(runif(n, 5, 10)),
Job_Satisfaction_T4 = round(runif(n, 5, 10)),
Life_Satisfaction_T1 = round(correlated_data[,1] * 2 + 7),
Life_Satisfaction_T2 = round(correlated_data[,2] * 2 + 7),
Life_Satisfaction_T3 = round(correlated_data[,3] * 2 + 7),
Life_Satisfaction_T4 = round(correlated_data[,4] * 2 + 7)
)
head(data_wide)
# Load necessary packages
if (!("lavaan" %in% installed.packages())) install.packages("lavaan")
library(lavaan)
# Specify the multivariate latent growth curve model
model <- '
# Intercept and slope factors for variable 1
i_var1 =~ 1*time1_var1 + 1*time2_var1 + 1*time3_var1
s_var1 =~ 0*time1_var1 + 1*time2_var1 + 2*time3_var1
# Intercept and slope factors for variable 2
i_var2 =~ 1*time1_var2 + 1*time2_var2 + 1*time3_var2
s_var2 =~ 0*time1_var2 + 1*time2_var2 + 2*time3_var2
'
# Estimate the model
fit <- lavaan::sem(model, data = data_wide)
# Setting the seed for reproducibility
set.seed(123)
# Setting the number of individuals for our sample data
n <- 500
# Specifying the desired correlation matrix for our data
cor_matrix <- matrix(c(1, 0.3, 0.3, 0.3,
0.3, 1, 0.3, 0.3,
0.3, 0.3, 1, 0.3,
0.3, 0.3, 0.3, 1),
nrow=4)
# Using Cholesky decomposition to generate correlated data
cholesky <- chol(cor_matrix)
# Generating correlated random data
random_data <- matrix(rnorm(n * 4), ncol=4)
correlated_data <- random_data %*% cholesky
# Converting the generated data into a structured data frame in wide format
data_wide <- data.frame(
Individual = 1:n,
Job_Satisfaction_T1 = round(runif(n, 5, 10)),
Job_Satisfaction_T2 = round(runif(n, 5, 10)),
Job_Satisfaction_T3 = round(runif(n, 5, 10)),
Job_Satisfaction_T4 = round(runif(n, 5, 10)),
Life_Satisfaction_T1 = round(correlated_data[,1] * 2 + 7),
Life_Satisfaction_T2 = round(correlated_data[,2] * 2 + 7),
Life_Satisfaction_T3 = round(correlated_data[,3] * 2 + 7),
Life_Satisfaction_T4 = round(correlated_data[,4] * 2 + 7)
)
head(data_wide)
# Load necessary packages
if (!("lavaan" %in% installed.packages())) install.packages("lavaan")
library(lavaan)
# Specify the multivariate latent growth curve model
model <- '
# Intercept and slope factors for variable 1
i_var1 =~ 1*Job_Satisfaction_T1 + 1*Job_Satisfaction_T2 + 1*Job_Satisfaction_T3
s_var1 =~ 0*Job_Satisfaction_T1 + 1*Job_Satisfaction_T2 + 2*Job_Satisfaction_T3
# Intercept and slope factors for variable 2
i_var2 =~ 1*Job_Satisfaction_T1 + 1*Job_Satisfaction_T2 + 1*Job_Satisfaction_T3
s_var2 =~ 0*Job_Satisfaction_T1 + 1*Job_Satisfaction_T2 + 2*Job_Satisfaction_T3
'
# Estimate the model
fit <- lavaan::sem(model, data = data_wide)
summary(fit, fit.measures=TRUE, standardized=TRUE, rsquare=TRUE)
set.seed(42)
n <- 500
# Generate three indicators for time 1
time1_ind1 <- rbinom(n, size = 1, prob = 0.7)
time1_ind2 <- rbinom(n, size = 1, prob = 0.6)
time1_ind3 <- rbinom(n, size = 1, prob = 0.5)
# Generate three indicators for time 2
time2_ind1 <- rbinom(n, size = 1, prob = 0.6)
time2_ind2 <- rbinom(n, size = 1, prob = 0.5)
time2_ind3 <- rbinom(n, size = 1, prob = 0.4)
# Generate three indicators for time 3
time3_ind1 <- rbinom(n, size = 1, prob = 0.5)
time3_ind2 <- rbinom(n, size = 1, prob = 0.4)
time3_ind3 <- rbinom(n, size = 1, prob = 0.3)
# Generate three indicators for time 4
time4_ind1 <- rbinom(n, size = 1, prob = 0.4)
time4_ind2 <- rbinom(n, size = 1, prob = 0.3)
time4_ind3 <- rbinom(n, size = 1, prob = 0.2)
data <- data.frame(time1_ind1, time1_ind2, time1_ind3,
time2_ind1, time2_ind2, time2_ind3,
time3_ind1, time3_ind2, time3_ind3,
time4_ind1, time4_ind2, time4_ind3)
# Load necessary packages
if (!("tidyLPA" %in% installed.packages())) install.packages("tidyLPA")
library(tidyLPA)
# Estimate the LTA model
fit <- tidyLPA::estimate_profiles(data, 2, variances = "equal", covariances = "zero")
summary(fit, fit.measures=TRUE, standardized=TRUE, rsquare=TRUE)
plot(fit)
set.seed(1234)
n <- 500  # number of participants
data <- data.frame(
id = 1:n,
T1 = sample(1:5, n, replace = TRUE),
T2 = sample(1:5, n, replace = TRUE),
T3 = sample(1:5, n, replace = TRUE)
set.seed(1234)
n <- 500  # number of participants
data <- data.frame(
id = 1:n,
T1 = sample(1:5, n, replace = TRUE),
T2 = sample(1:5, n, replace = TRUE),
T3 = sample(1:5, n, replace = TRUE)
)
# Load necessary packages
if (!("lavaan" %in% installed.packages())) install.packages("tidyLPA")
library(lavaan)
# Model for Time 1
model_T1 <- '
# Latent class variable
c =~ T1
'
# Model for Time 2
model_T2 <- '
# Latent class variable
c =~ T2
'
# Model for Time 3
model_T3 <- '
# Latent class variable
c =~ T3
'
fit_T1 <- sem(model_T1, data = data, fixed.x = FALSE, ordered = "T1")
summary(fit_T1)
fit_T2 <- sem(model_T2, data = data, fixed.x = FALSE, ordered = "T2")
summary(fit_T1)
fit_T3 <- sem(model_T3, data = data, fixed.x = FALSE, ordered = "T3")
summary(fit_T1)
# LTA model (assuming 3 latent classes)
model_LTA <- '
# Transition from T1 to T2
c2 ~ c1
# Transition from T2 to T3
c3 ~ c2
'
fit_LTA <- sem(model_LTA, data = data, fixed.x = FALSE, ordered = c("T1", "T2", "T3"))
set.seed(1234)
n <- 200  # number of participants
# Simulate data based on the above assumptions
T1 <- sample(1:3, n, replace = TRUE, prob = c(0.4, 0.4, 0.2))
T2 <- ifelse(T1 == 1, sample(1:3, n, replace = TRUE, prob = c(0.2, 0.7, 0.1)),
ifelse(T1 == 2, sample(2:3, n, replace = TRUE, prob = c(0.6, 0.4)),
sample(2:3, n, replace = TRUE, prob = c(0.3, 0.7))))
T3 <- ifelse(T2 == 1, sample(1:3, n, replace = TRUE, prob = c(0.2, 0.7, 0.1)),
ifelse(T2 == 2, sample(2:3, n, replace = TRUE, prob = c(0.6, 0.4)),
sample(2:3, n, replace = TRUE, prob = c(0.3, 0.7))))
data <- data.frame(
id = 1:n,
T1 = T1,
T2 = T2,
T3 = T3
)
# Load necessary packages
if (!("lavaan" %in% installed.packages())) install.packages("tidyLPA")
library(lavaan)
library(lavaan)
# Fit separate latent class models for each time point
# Time 1
model_T1 <- '
# Three latent classes for T1
c1 =~ T1
c2 =~ T1
c3 =~ T1
'
fit_T1 <- sem(model_T1, data = data, fixed.x = FALSE, ordered = "T1")
# Time 2
model_T2 <- '
# Three latent classes for T2
c1 =~ T2
c2 =~ T2
c3 =~ T2
'
fit_T2 <- sem(model_T2, data = data, fixed.x = FALSE, ordered = "T2")
# Time 3
model_T3 <- '
# Three latent classes for T3
c1 =~ T3
c2 =~ T3
c3 =~ T3
'
fit_T3 <- sem(model_T3, data = data, fixed.x = FALSE, ordered = "T3")
# Now, estimate transition probabilities between the latent classes
# Transition from Time 1 to Time 2
model_transition_12 <- '
# From T1 classes to T2 classes
T2.c1 ~ c(T1.c1_to_T2.c1, T1.c2_to_T2.c1, T1.c3_to_T2.c1) * c(T1.c1, T1.c2, T1.c3)
T2.c2 ~ c(T1.c1_to_T2.c2, T1.c2_to_T2.c2, T1.c3_to_T2.c2) * c(T1.c1, T1.c2, T1.c3)
T2.c3 ~ c(T1.c1_to_T2.c3, T1.c2_to_T2.c3, T1.c3_to_T2.c3) * c(T1.c1, T1.c2, T1.c3)
'
fit_transition_12 <- sem(model_transition_12, data = data)
## Generating a Simulated Dataset
We'll create a dataset where individuals can belong to one of two latent states across three time points. Transitions between states will be simulated based on predefined probabilities.
```{r}
# Install and load necessary packages
if (!require(LMest)) install.packages("LMest")
library(LMest)
set.seed(123)
# Number of individuals
n <- 500
# Transition probabilities
P <- matrix(c(0.8, 0.2, 0.3, 0.7), ncol=2)
# Initial state probabilities
pi <- c(0.6, 0.4)
# Function to simulate data based on transition probabilities
simulate_data <- function(n, pi, P) {
states <- matrix(0, nrow=n, ncol=3)
states[,1] <- sample(1:2, n, replace=TRUE, prob=pi)
for (i in 2:3) {
for (j in 1:n) {
states[j,i] <- sample(1:2, 1, replace=TRUE, prob=P[states[j,i-1],])
}
}
return(states)
}
data <- simulate_data(n, pi, P)
result <- LMbase(data)
summary(result)
# Install and load necessary packages
if (!require(LMest)) install.packages("LMest")
library(LMest)
set.seed(123)
# Number of individuals
n <- 500
# Transition probabilities
P <- matrix(c(0.8, 0.2, 0.3, 0.7), ncol=2)
# Initial state probabilities
pi <- c(0.6, 0.4)
# Function to simulate data based on transition probabilities
simulate_data <- function(n, pi, P) {
states <- matrix(0, nrow=n, ncol=3)
states[,1] <- sample(1:2, n, replace=TRUE, prob=pi)
for (i in 2:3) {
for (j in 1:n) {
states[j,i] <- sample(1:2, 1, replace=TRUE, prob=P[states[j,i-1],])
}
}
return(states)
}
data <- simulate_data(n, pi, P)
result <- LMbase(data)
# Install and load necessary packages
if (!require(LMest)) install.packages("LMest")
library(LMest)
set.seed(123)
# Number of individuals
n <- 500
# Transition probabilities
P <- matrix(c(0.8, 0.2, 0.3, 0.7), ncol=2)
# Initial state probabilities
pi <- c(0.6, 0.4)
# Function to simulate data based on transition probabilities
simulate_data <- function(n, pi, P) {
states <- matrix(0, nrow=n, ncol=3)
states[,1] <- sample(1:2, n, replace=TRUE, prob=pi)
for (i in 2:3) {
for (j in 1:n) {
states[j,i] <- sample(1:2, 1, replace=TRUE, prob=P[states[j,i-1],])
}
}
return(states)
}
data <- simulate_data(n, pi, P)
# Fitting a Latent Transition Model using `LMest`
result <- LMM(data, nStates=2, nInd=n, nTimes=3)
ls("package:LMest")
# Install and load necessary packages
if (!require(LMest)) install.packages("LMest")
library(LMest)
set.seed(123)
# Number of individuals
n <- 500
# Transition probabilities
P <- matrix(c(0.8, 0.2, 0.3, 0.7), ncol=2)
# Initial state probabilities
pi <- c(0.6, 0.4)
# Function to simulate data based on transition probabilities
simulate_data <- function(n, pi, P) {
states <- matrix(0, nrow=n, ncol=3)
states[,1] <- sample(1:2, n, replace=TRUE, prob=pi)
for (i in 2:3) {
for (j in 1:n) {
states[j,i] <- sample(1:2, 1, replace=TRUE, prob=P[states[j,i-1],])
}
}
return(states)
}
data <- simulate_data(n, pi, P)
# Fitting a Latent Transition Model using `LMest`
result <- est_lm_basic(data, nStates=2)
set.seed(123)
n <- 500
timepoints <- 4
n_class <- round(n / 3)  # Number of observations for each class
# Simulate the data for each class
class1 <- data.frame(id = 1:n_class,
time = rep(1:timepoints, each = n_class),
class = 1,
value = rnorm(n_class * timepoints, mean = 1 + 0.5 * (1:timepoints), sd = 0.5))
class2 <- data.frame(id = (n_class + 1):(2 * n_class),
time = rep(1:timepoints, each = n_class),
class = 2,
value = rnorm(n_class * timepoints, mean = 2 - 0.3 * (1:timepoints), sd = 0.5))
class3 <- data.frame(id = (2 * n_class + 1):(3 * n_class),
time = rep(1:timepoints, each = n_class),
class = 3,
value = rnorm(n_class * timepoints, mean = 3 + 0.1 * (1:timepoints), sd = 0.5))
# Combine the data from all classes
data <- rbind(class1, class2, class3)
# Install the lcmm package if not already installed
if (!("lcmm" %in% installed.packages())) {
install.packages("lcmm")
}
library(lcmm)
# Fit the Growth Mixture Model
gmm <- hlme(value ~ time,
random = ~ time,
subject = "id",
mixture = ~ time,
data = data,
ng = 3)
set.seed(123)
n <- 500
timepoints <- 4
n_class <- round(n / 3)  # Number of observations for each class
# Simulate the data for each class
class1 <- data.frame(id = 1:n_class,
time = rep(1:timepoints, each = n_class),
class = 1,
value = rnorm(n_class * timepoints, mean = 1 + 0.5 * (1:timepoints), sd = 0.5))
class2 <- data.frame(id = (n_class + 1):(2 * n_class),
time = rep(1:timepoints, each = n_class),
class = 2,
value = rnorm(n_class * timepoints, mean = 2 - 0.3 * (1:timepoints), sd = 0.5))
class3 <- data.frame(id = (2 * n_class + 1):(3 * n_class),
time = rep(1:timepoints, each = n_class),
class = 3,
value = rnorm(n_class * timepoints, mean = 3 + 0.1 * (1:timepoints), sd = 0.5))
# Combine the data from all classes
data <- rbind(class1, class2, class3)
# Install the lcmm package if not already installed
if (!("lcmm" %in% installed.packages())) {
install.packages("lcmm")
}
library(lcmm)
# Fit the Growth Mixture Model
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'ID',
ng = 2, # number of latent classes
data = data)
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Setting the seed for reproducibility
set.seed(123)
# Setting the number of individuals for our sample data
n <- 500
# Specifying the desired correlation matrix for our data (5x5 matrix for 5 timepoints)
cor_matrix <- matrix(c(1, 0.3, 0.3, 0.3, 0.3,
0.3, 1, 0.3, 0.3, 0.3,
0.3, 0.3, 1, 0.3, 0.3,
0.3, 0.3, 0.3, 1, 0.3,
0.3, 0.3, 0.3, 0.3, 1),
nrow=5)
# Using Cholesky decomposition to generate correlated data
cholesky <- chol(cor_matrix)
# Generating correlated random data for 5 timepoints
random_data <- matrix(rnorm(n * 5), ncol=5)
correlated_data <- random_data %*% cholesky
# Converting the generated data into a structured data frame in wide format
data_wide <- data.frame(
Individual = 1:n,
Job_Satisfaction_T1 = round(runif(n, 5, 10)),
Job_Satisfaction_T2 = round(runif(n, 5, 10)),
Job_Satisfaction_T3 = round(runif(n, 5, 10)),
Job_Satisfaction_T4 = round(runif(n, 5, 10)),
Job_Satisfaction_T5 = round(runif(n, 5, 10)),
Life_Satisfaction_T1 = round(correlated_data[,1] * 2 + 7),
Life_Satisfaction_T2 = round(correlated_data[,2] * 2 + 7),
Life_Satisfaction_T3 = round(correlated_data[,3] * 2 + 7),
Life_Satisfaction_T4 = round(correlated_data[,4] * 2 + 7),
Life_Satisfaction_T5 = round(correlated_data[,5] * 2 + 7)
)
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual',
ng = 2, # number of latent classes
data = subset(data_long, Variable == "Life_Satisfaction"))
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual', ng = 2, # number of latent classes data = subset(data_long, Variable == "Life_Satisfaction"))
# Examine the results
summary(gmm_model)
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual',
ng = 2, # specifying number of latent classes
data = subset(data_long, Variable == "Life_Satisfaction"))
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual',
mixture = ~ Time,
ng = 2, # specifying number of latent classes
data = subset(data_long, Variable == "Life_Satisfaction"))
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Specify initial values
Bfixed <- c(7, 0.5) # Initial values for intercept and slope
Brand <- c(7, 0.5)  # Initial values for random intercept and slope
Bmix <- c(0.5, 0.5) # Initial values for mixture intercept and slope
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual',
mixture = ~ Time,
ng = 2, # specifying number of latent classes
B = list(fixed = Bfixed, random = Brand, mixture = Bmix),
data = subset(data_long, Variable == "Life_Satisfaction"))
# Load necessary libraries
library(lcmm)
library(tidyr)
# Convert wide format data to long format
data_long <- data_wide %>%
gather(key = "Variable_Time", value = "Score", -Individual) %>%
separate(Variable_Time, into = c("Variable", "Time"), sep = "_T")
# Specify initial values
Bfixed <- c(7, 0.5, 7, 0.5) # Initial values for intercept and slope for each class
Brand <- c(7, 0.5, 4, 0.2, 0.1)  # Initial values for random intercept, slope, their variances, and covariance
Bmix <- c(7, 0.5, 7, 0.5) # Initial values for mixture intercept and slope for each class
# Fit the GMM for Life Satisfaction across 5 time points
gmm_model <- lcmm(Score ~ Time, random = ~ Time, subject = 'Individual',
mixture = ~ Time,
ng = 2, # specifying number of latent classes
B = list(fixed = Bfixed, random = Brand, mixture = Bmix),
data = subset(data_long, Variable == "Life_Satisfaction"))
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
row <- paste(dat[i, ], collapse = "")
