#| output: FALSE
library(tidyverse)    # Collection of R packages for data science
library(rstatix)      # Pipe-friendly framework for basic statistical tests
library(DT)           # Rendering interactive data tables
library(lme4)         # Linear mixed-effects models
library(report)       # Easy reporting of regression analyses
library(broom)        # Tidy and augment statistical models output
library(gridExtra)    # Arrange multiple grid-based plots on a page
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
#| cache: FALSE
# Set the data paths
data_path_1 <- "/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds"
data_path_2 <- "/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds"
# Read the data
data_demographics <- readRDS(data_path_1)
data_nonimaging <- readRDS(data_path_2)
# Subset the nonimaging data to include desired variables
selected_vars <- c("src_subject_id", "eventname", "nihtbx_totalcomp_fc", "anthroweightcalc", "anthroheightcalc")
subset_data <- data_nonimaging[, selected_vars]
library(dplyr)
# # Merge the datasets on 'src_subject_id' and 'eventname'
merged_data <- data_demographics %>%
full_join(subset_data, by = c("src_subject_id", "eventname"))
# Inspect the merged data structure
str(merged_data)
# Define event names to be retained in the analysis and convert variables to appropriate data types
eventnames_to_include <- c("baseline_year_1_arm_1",
"1_year_follow_up_y_arm_1",
"2_year_follow_up_y_arm_1",
"3_year_follow_up_y_arm_1",
"4_year_follow_up_y_arm_1")
df <- merged_data %>%
filter(eventname %in% eventnames_to_include) %>%
mutate(
src_subject_id = as.factor(src_subject_id),
eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),
age = as.numeric(age),
sex = as.factor(sex),
race.4level = as.factor(race.4level),
hisp = as.factor(hisp),
high.educ.bl = as.factor(high.educ.bl),
household.income.bl = as.factor(household.income.bl),
acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),
rel_family_id.bl = as.factor(rel_family_id.bl),
site_id_l = as.factor(site_id_l),
nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),
anthroweightcalc = as.numeric(anthroweightcalc),
anthroheightcalc = as.numeric(anthroheightcalc)
) %>%
# Exclude cases from unused assessment waves
filter(!is.na(eventname))
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
# Define a function to compute descriptives
compute_descriptives <- function(data, event_name) {
# For factor variables
sex_desc <- paste0(table(data$sex), " (", round(100 * prop.table(table(data$sex)), 1), "%)")
race_desc <- paste0(table(data$race.4level), " (", round(100 * prop.table(table(data$race.4level)), 1), "%)")
# For numeric variables
age_desc <- paste0(round(mean(data$age, na.rm = TRUE), 2), " (", round(sd(data$age, na.rm = TRUE), 2), ")")
weight_desc <- paste0(round(mean(data$anthroweightcalc, na.rm = TRUE), 2), " (", round(sd(data$anthroweightcalc, na.rm = TRUE), 2), ")")
height_desc <- paste0(round(mean(data$anthroheightcalc, na.rm = TRUE), 2), " (", round(sd(data$anthroheightcalc, na.rm = TRUE), 2), ")")
# Combine into a data frame
desc_df <- data.frame(
Variable = c("Sex - Female", "Sex - Male or other", "Race - Asian", "Race - Black", "Race - Other/Mixed", "Race - White", "Age", "Weight", "Height"),
Value = c(sex_desc, race_desc, age_desc, weight_desc, height_desc)
)
# Rename the Value column based on event name
colnames(desc_df)[2] <- event_name
return(desc_df)
}
# Compute descriptives for each event
baseline_desc <- compute_descriptives(subset(df, eventname == "baseline_year_1_arm_1"), "baseline_year_1_arm_1")
one_year_desc <- compute_descriptives(subset(df, eventname == "1_year_follow_up_y_arm_1"), "1_year_follow_up_y_arm_1")
two_year_desc <- compute_descriptives(subset(df, eventname == "2_year_follow_up_y_arm_1"), "2_year_follow_up_y_arm_1")
three_year_desc <- compute_descriptives(subset(df, eventname == "3_year_follow_up_y_arm_1"), "3_year_follow_up_y_arm_1")
# Join all data frames side-by-side
final_table <- baseline_desc %>%
left_join(one_year_desc, by = "Variable") %>%
left_join(two_year_desc, by = "Variable") %>%
left_join(three_year_desc, by = "Variable")
# Adjust for the required format
final_table[1:6, 3:5] <- NA
# Round numeric values to two decimal places
numeric_cols <- sapply(final_table, is.numeric)
final_table[numeric_cols] <- lapply(final_table[numeric_cols], round, 2)
# Create heading rows with the same columns as final_table
heading_rows <- data.frame(
Variable = c("Sex", "Race"),
baseline_year_1_arm_1 = NA_real_,
`1_year_follow_up_y_arm_1` = NA_real_,
`2_year_follow_up_y_arm_1` = NA_real_,
`3_year_follow_up_y_arm_1` = NA_real_
)
# Set column names of heading_rows to match final_table
colnames(heading_rows) <- colnames(final_table)
# Introduce group labels and adjust the "Variable" column
final_table <- rbind(
heading_rows[1,],
final_table[1:2,],
heading_rows[2,],
final_table[3:6,],
final_table[7:9,]
)
# Update the Variable column to remove redundant factor variable name
final_table$Variable <- gsub("Sex - ", "", final_table$Variable)
final_table$Variable <- gsub("Race - ", "", final_table$Variable)
final_table$Variable[final_table$Variable == "Male or other"] <- "Male"
# Add non-breaking spaces for increased indentation
final_table$Variable[final_table$Variable %in% c("Female", "Male", "Asian", "Black", "Other/Mixed", "White")] <-
paste0(rep("&nbsp;", 6), final_table$Variable[final_table$Variable %in% c("Female", "Male", "Asian", "Black", "Other/Mixed", "White")])
# Update column headers
colnames(final_table)[2:5] <- c("Baseline", "Year 1", "Year 2", "Year 3")
# Display the table interactively without row names, with updated column headers, and with HTML entities rendered
datatable(final_table,
colnames = c("", "Baseline", "Year 1", "Year 2", "Year 3"),
options = list(pageLength = nrow(final_table), autoWidth = TRUE),
rownames = FALSE, escape = FALSE,
caption = "Descriptives Table")  # Add table title
#| class.source: 'fold-hide'
#| message: FALSE
#| warning: FALSE
#| echo: TRUE
## Linear Mixed Model with a random intercept (LMM-ri)
model <- lmer(anthroheightcalc ~ 1 + eventname + sex + (1|src_subject_id), data = df, REML=T)
print(model)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| code-summary: testing
## Output and reports extending from the LMM-ri analyses
summary(model)
confint(model, level = 0.95, method = "Wald")
report_performance(model)
# Extract the random effects
random_effects <- ranef(model)[[1]]
# Convert to dataframe
random_effects_df <- data.frame(Intercept = random_effects$`(Intercept)`)
# Plot 1: Histogram
hist_plot <- ggplot(random_effects_df, aes(x = Intercept)) +
geom_histogram(aes(y = ..density..), bins = 30, color = "black", fill = "lightblue") + labs(title = "Histogram of Random Effects", x = "Random Intercept Values", y = "Density") +
theme_minimal()
# Plot 2: Residuals vs Fitted Values
resid_plot <- ggplot(NULL, aes(x = fitted_values, y = residuals)) +
geom_point(alpha = 0.5) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
theme_minimal()
# Extract the data frame used in the model
model_data <- model@frame
# Extract unique subject IDs from the model's data
original_subject_ids <- unique(model_data$src_subject_id)
# Subset the original data to include only those subjects
df_subset <- df %>% filter(src_subject_id %in% original_subject_ids)
eventname_map <- c(
"baseline_year_1_arm_1" = "Baseline",
"1_year_follow_up_y_arm_1" = "Year_1",
"2_year_follow_up_y_arm_1" = "Year_2",
"3_year_follow_up_y_arm_1" = "Year_3",
"4_year_follow_up_y_arm_1" = "Year_4"
)
# Apply the recoding to the eventname variable
df_subset$eventname <- factor(df_subset$eventname, levels = names(eventname_map), labels = eventname_map)
# Verify the recoding
table(df_subset$eventname)
# Generate the plot
ggplot(df_subset, aes(x = eventname, y = anthroheightcalc, group = src_subject_id)) +
# Individual estimated height trajectories in faded lines
geom_line(aes(group = src_subject_id), alpha = 0.3, color = "grey50") +
# Overall group-mean trajectory in blue with increased thickness
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "blue", linewidth = 1) +
labs(title = "Individual and Group-Mean Height Trajectories",
x = "Event Name",
y = "Height") +
theme_minimal()
#| echo: false
## Creating variable (names) from output to be used for inline text
library(broom.mixed)
tidyfit <- tidy(model)
tidyaugment <- augment(model)
tidyglance <- glance(model)
#Life_Satisfaction_T1_estimate <- round(tidyfit[tidyfit$term == "Life_Satisfaction_T1", "estimate"], 3)
#Life_Satisfaction_T1_pvalue <- round(tidyfit[tidyfit$term == "Life_Satisfaction_T1", "p.value"], 3)
# Extract values from the tibble for inline text
#Life_Satisfaction_T1_estimate <- Life_Satisfaction_T1_estimate$estimate
#Life_Satisfaction_T1_pvalue <- Life_Satisfaction_T1_pvalue$p.value
View(tidyfit)
rm(list=ls())
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
# Create a list of required packages
packages_required <- c("tidyverse","rstatix","DT","lme4","report","broom","gridExtra")
# Check which packages are not installed and install them
packages_to_install <- setdiff(packages_required, rownames(installed.packages()))
if (length(packages_to_install) > 0) {
install.packages(packages_to_install)
}
# Load the required packages
lapply(packages_required, library, character.only = TRUE)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
library(tidyverse)    # Collection of R packages for data science
library(rstatix)      # Pipe-friendly framework for basic statistical tests
library(DT)           # Rendering interactive data tables
library(lme4)         # Linear mixed-effects models
library(report)       # Easy reporting of regression analyses
library(broom)        # Tidy and augment statistical models output
library(gridExtra)    # Arrange multiple grid-based plots on a page
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F,
comment=NA, cache=T, code_folding=T,
R.options=list(width=220, digits = 3),
fig.align='center',
out.width='75%', fig.asp=.75)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
#| cache: FALSE
# Set the data paths
data_path_1 <- "/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds"
data_path_2 <- "/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds"
# Read the data
data_demographics <- readRDS(data_path_1)
data_nonimaging <- readRDS(data_path_2)
# Subset the nonimaging data to include desired variables
selected_vars <- c("src_subject_id", "eventname", "nihtbx_totalcomp_fc", "anthroweightcalc", "anthroheightcalc")
subset_data <- data_nonimaging[, selected_vars]
library(dplyr)
# # Merge the datasets on 'src_subject_id' and 'eventname'
merged_data <- data_demographics %>%
full_join(subset_data, by = c("src_subject_id", "eventname"))
# Inspect the merged data structure
str(merged_data)
# Define event names to be retained in the analysis and convert variables to appropriate data types
eventnames_to_include <- c("baseline_year_1_arm_1",
"1_year_follow_up_y_arm_1",
"2_year_follow_up_y_arm_1",
"3_year_follow_up_y_arm_1",
"4_year_follow_up_y_arm_1")
df <- merged_data %>%
filter(eventname %in% eventnames_to_include) %>%
mutate(
src_subject_id = as.factor(src_subject_id),
eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),
age = as.numeric(age),
sex = as.factor(sex),
race.4level = as.factor(race.4level),
hisp = as.factor(hisp),
high.educ.bl = as.factor(high.educ.bl),
household.income.bl = as.factor(household.income.bl),
acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),
rel_family_id.bl = as.factor(rel_family_id.bl),
site_id_l = as.factor(site_id_l),
nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),
anthroweightcalc = as.numeric(anthroweightcalc),
anthroheightcalc = as.numeric(anthroheightcalc)
) %>%
# Exclude cases from unused assessment waves
filter(!is.na(eventname))
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
# Define a function to compute descriptives
compute_descriptives <- function(data, event_name) {
# For factor variables
sex_desc <- paste0(table(data$sex), " (", round(100 * prop.table(table(data$sex)), 1), "%)")
race_desc <- paste0(table(data$race.4level), " (", round(100 * prop.table(table(data$race.4level)), 1), "%)")
# For numeric variables
age_desc <- paste0(round(mean(data$age, na.rm = TRUE), 2), " (", round(sd(data$age, na.rm = TRUE), 2), ")")
weight_desc <- paste0(round(mean(data$anthroweightcalc, na.rm = TRUE), 2), " (", round(sd(data$anthroweightcalc, na.rm = TRUE), 2), ")")
height_desc <- paste0(round(mean(data$anthroheightcalc, na.rm = TRUE), 2), " (", round(sd(data$anthroheightcalc, na.rm = TRUE), 2), ")")
# Combine into a data frame
desc_df <- data.frame(
Variable = c("Sex - Female", "Sex - Male or other", "Race - Asian", "Race - Black", "Race - Other/Mixed", "Race - White", "Age", "Weight", "Height"),
Value = c(sex_desc, race_desc, age_desc, weight_desc, height_desc)
)
# Rename the Value column based on event name
colnames(desc_df)[2] <- event_name
return(desc_df)
}
# Compute descriptives for each event
baseline_desc <- compute_descriptives(subset(df, eventname == "baseline_year_1_arm_1"), "baseline_year_1_arm_1")
one_year_desc <- compute_descriptives(subset(df, eventname == "1_year_follow_up_y_arm_1"), "1_year_follow_up_y_arm_1")
two_year_desc <- compute_descriptives(subset(df, eventname == "2_year_follow_up_y_arm_1"), "2_year_follow_up_y_arm_1")
three_year_desc <- compute_descriptives(subset(df, eventname == "3_year_follow_up_y_arm_1"), "3_year_follow_up_y_arm_1")
# Join all data frames side-by-side
final_table <- baseline_desc %>%
left_join(one_year_desc, by = "Variable") %>%
left_join(two_year_desc, by = "Variable") %>%
left_join(three_year_desc, by = "Variable")
# Adjust for the required format
final_table[1:6, 3:5] <- NA
# Round numeric values to two decimal places
numeric_cols <- sapply(final_table, is.numeric)
final_table[numeric_cols] <- lapply(final_table[numeric_cols], round, 2)
# Create heading rows with the same columns as final_table
heading_rows <- data.frame(
Variable = c("Sex", "Race"),
baseline_year_1_arm_1 = NA_real_,
`1_year_follow_up_y_arm_1` = NA_real_,
`2_year_follow_up_y_arm_1` = NA_real_,
`3_year_follow_up_y_arm_1` = NA_real_
)
# Set column names of heading_rows to match final_table
colnames(heading_rows) <- colnames(final_table)
# Introduce group labels and adjust the "Variable" column
final_table <- rbind(
heading_rows[1,],
final_table[1:2,],
heading_rows[2,],
final_table[3:6,],
final_table[7:9,]
)
# Update the Variable column to remove redundant factor variable name
final_table$Variable <- gsub("Sex - ", "", final_table$Variable)
final_table$Variable <- gsub("Race - ", "", final_table$Variable)
final_table$Variable[final_table$Variable == "Male or other"] <- "Male"
# Add non-breaking spaces for increased indentation
final_table$Variable[final_table$Variable %in% c("Female", "Male", "Asian", "Black", "Other/Mixed", "White")] <-
paste0(rep("&nbsp;", 6), final_table$Variable[final_table$Variable %in% c("Female", "Male", "Asian", "Black", "Other/Mixed", "White")])
# Update column headers
colnames(final_table)[2:5] <- c("Baseline", "Year 1", "Year 2", "Year 3")
# Display the table interactively without row names, with updated column headers, and with HTML entities rendered
datatable(final_table,
colnames = c("", "Baseline", "Year 1", "Year 2", "Year 3"),
options = list(pageLength = nrow(final_table), autoWidth = TRUE),
rownames = FALSE, escape = FALSE,
caption = "Descriptives Table")  # Add table title
#| class.source: 'fold-hide'
#| message: FALSE
#| warning: FALSE
#| echo: TRUE
## Linear Mixed Model with a random intercept (LMM-ri)
model <- lmer(anthroheightcalc ~ 1 + eventname + sex + (1|src_subject_id), data = df, REML=T)
print(model)
#| echo: TRUE
#| messages: FALSE
#| warning: FALSE
#| code-summary: testing
## Output and reports extending from the LMM-ri analyses
summary(model)
confint(model, level = 0.95, method = "Wald")
report_performance(model)
# Extract the random effects
random_effects <- ranef(model)[[1]]
# Convert to dataframe
random_effects_df <- data.frame(Intercept = random_effects$`(Intercept)`)
# Plot 1: Histogram
hist_plot <- ggplot(random_effects_df, aes(x = Intercept)) +
geom_histogram(aes(y = ..density..), bins = 30, color = "black", fill = "lightblue") + labs(title = "Histogram of Random Effects", x = "Random Intercept Values", y = "Density") +
theme_minimal()
# Plot 2: Residuals vs Fitted Values
resid_plot <- ggplot(NULL, aes(x = fitted_values, y = residuals)) +
geom_point(alpha = 0.5) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
theme_minimal()
# Extract the data frame used in the model
model_data <- model@frame
# Extract unique subject IDs from the model's data
original_subject_ids <- unique(model_data$src_subject_id)
# Subset the original data to include only those subjects
df_subset <- df %>% filter(src_subject_id %in% original_subject_ids)
eventname_map <- c(
"baseline_year_1_arm_1" = "Baseline",
"1_year_follow_up_y_arm_1" = "Year_1",
"2_year_follow_up_y_arm_1" = "Year_2",
"3_year_follow_up_y_arm_1" = "Year_3",
"4_year_follow_up_y_arm_1" = "Year_4"
)
# Apply the recoding to the eventname variable
df_subset$eventname <- factor(df_subset$eventname, levels = names(eventname_map), labels = eventname_map)
# Verify the recoding
table(df_subset$eventname)
# Generate the plot
ggplot(df_subset, aes(x = eventname, y = anthroheightcalc, group = src_subject_id)) +
# Individual estimated height trajectories in faded lines
geom_line(aes(group = src_subject_id), alpha = 0.3, color = "grey50") +
# Overall group-mean trajectory in blue with increased thickness
stat_summary(aes(group = 1), fun = mean, geom = "line", color = "blue", linewidth = 1) +
labs(title = "Individual and Group-Mean Height Trajectories",
x = "Event Name",
y = "Height") +
theme_minimal()
#| echo: false
## Creating variable (names) from output to be used for inline text
library(broom.mixed)
tidyfit <- tidy(model)
tidyaugment <- augment(model)
tidyglance <- glance(model)
#Life_Satisfaction_T1_estimate <- round(tidyfit[tidyfit$term == "Life_Satisfaction_T1", "estimate"], 3)
#Life_Satisfaction_T1_pvalue <- round(tidyfit[tidyfit$term == "Life_Satisfaction_T1", "p.value"], 3)
# Extract values from the tibble for inline text
#Life_Satisfaction_T1_estimate <- Life_Satisfaction_T1_estimate$estimate
#Life_Satisfaction_T1_pvalue <- Life_Satisfaction_T1_pvalue$p.value
View(tidyaugment)
View(tidyfit)
View(tidyglance)
Intercept_estimate <- round(tidyfit[tidyfit$term == "(Intercept)", "estimate"], 3)
Intercept_pvalue <- round(tidyfit[tidyfit$term == "(Intercept)", "p.value"], 3)
#| echo: false
## Creating variable (names) from output to be used for inline text
library(broom.mixed)
tidyfit <- tidy(model)
tidyaugment <- augment(model)
tidyglance <- glance(model)
Intercept_estimate <- round(tidyfit[tidyfit$term == "(Intercept)", "estimate"], 3)
#Intercept_pvalue <- round(tidyfit[tidyfit$term == "(Intercept)", "p.value"], 3)
# Extract values from the tibble for inline text
Intercept_estimate <- Intercept_estimate$estimate
#Intercept_pvalue <- Intercept_pvalue$p.value
Intercept_SE <- round(tidyfit[tidyfit$term == "(Intercept)", "std.error"], 3)
Intercept_SE <- Intercept_SE$std.error
library(readxl)
FitbitDataWeeklyAverageTime2Y <- read_excel("~/Library/CloudStorage/GoogleDrive-swh004@gmail.com/My Drive/Projects/Collaborators/Chritine/FitbitDataWeeklyAverageTime2Y.csv")
library(readr)
FitbitDataWeeklyAverageTime2Y <- read_csv("~/Library/CloudStorage/GoogleDrive-swh004@gmail.com/My Drive/Projects/Collaborators/Chritine/FitbitDataWeeklyAverageTime2Y.csv")
View(FitbitDataWeeklyAverageTime2Y)
#Histogram weekly total minutes of light activity
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_light_active_min,
xlab="Sum of Minutes Spent in Light Activity",
main="Weekly Minutes of Light Activity",col="light blue")
#Histogram weekly total minutes of light activity
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_light_active_min,
xlab="Sum of Minutes Spent in Light Activity",
main="Weekly Minutes of Light Activity",col="light blue")
#Mean weekly total minutes of light activity
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_light_active_min)
#Standard Deviation weekly total minutes of light activity
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_light_active_min)
#Range weekly total minutes of light activity
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_light_active_min)
#Histogram weekly total minutes of fairly active
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_farily_active_min,
xlab="Total Minutes per Valid Day",
main="Sum of Minutes Spent Fairly Active",col="blue")
#Mean weekly total minutes of fairly active
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_farily_active_min)
#Standard Deviation weekly total minutes of fairly active
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_farily_active_min)
#Range weekly total minutes of fairly active
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_farily_active_min)
#Histogram weekly total minutes of very active
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_very_active_min,
xlab="Total Minutes per Valid Day",
main="Sum of Minutes Spent Very Active",col="darkblue")
#Mean weekly total minutes of very active
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_very_active_min)
#Standard Deviation weekly total minutes of very active
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_very_active_min)
#Range weekly total minutes of fairly active
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_very_active_min)
#Histogram weekly average minutes per valid day light activity
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_light_active_min,
xlab="Weekly Average Minutes per Valid Day",
main="Average Minutes Spent Light Active",col="lightblue")
#Mean weekly average minutes per valid day light activity
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_light_active_min)
#Standard deviation weekly average minutes per valid day light activity
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_light_active_min)
#Range weekly average minutes per valid day light activity
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_light_active_min)
#Histogram weekly average minutes per valid day fairly active
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_farily_at_min,
xlab="Weekly Average Minutes per Valid Day",
main="Average Minutes Spent Fairly Active",col="blue")
#Mean weekly average minutes per valid day fairly active
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_farily_at_min)
#Standard deviation weekly average minutes per valid day fairly active
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_farily_at_min)
#Range weekly average minutes per valid day fairly active
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_farily_at_min)
#Histogram weekly average minutes per valid day very active
hist(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_very_active_min,
xlab="Weekly Average Minutes per Valid Day",
main="Average Minutes Spent Very Active",col="darkblue")
#Mean weekly average minutes per valid day very active
mean(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_very_active_min)
#Standard deviation weekly average minutes per valid day very active
sd(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_very_active_min)
#Range weekly average minutes per valid day very active
range(FitbitDataWeeklyAverageTime2Y$fit_ss_wk_avg_very_active_min)
glance <-model %>% mutate(tidy = map(mod1, broom::tidy),
glance = map(model, broom::glance),
augment = map(model, broom::augment),
rsq = glance %>% map_dbl('r.squared'),
slope = tidy %>% map_dbl(function(x) x$estimate[2]))
View(model)
model@resp[[".->weights"]]
model@frame[["sex"]]
model@pp[[".->RZX"]]
